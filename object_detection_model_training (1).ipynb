{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation: \n",
    "To train an object detection model on a custom dataset, there are 3 prerequisites:\n",
    "* Install TensorFlow\n",
    "* Install TensorFlow Object Detection API\n",
    "* Install labelImg (for dataset annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installing Anaconda is a useful tool for creating virtual environments and managing packages. However, it is optional. \n",
    "It's recommended to use a virtual environment. We can simply use pip to install tensorflow within the virtual environment:\n",
    "\n",
    "`!pip install tensorflow`\n",
    "\n",
    "Also will need to install the setup tools package for python:\n",
    "\n",
    "`apt-get install install -y python-setuptools`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing TensorFlow Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install Dependencies\n",
    "\n",
    "Installing and integrating the TensorFlow Object Detection API is slightly more involved than simply using pip to install a package, as the object detection API does not come packaged with TensorFlow. \n",
    "There are several prerequisites that must be installed first:\n",
    "* pillow\n",
    "* lxml\n",
    "* jupyter\n",
    "* matplotlib\n",
    "* opencv\n",
    "* cython\n",
    "\n",
    "These packages can be installed using anaconda by running:\n",
    "\n",
    "`conda install pillow, lxml, jupyter, matplotlib, opencv, cython`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively (recommended), one can use pip to install the dependencies. We also need to install the protobuf compiler:\n",
    "\n",
    "`apt-get install protobuf-compiler python-pil python-lxml python-tk -y`\n",
    "\n",
    "Then we can run the pip install commands:\n",
    "\n",
    "`pip install pillow lxml jupyter matplotlib opencv-python cython contextlib2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download TensorFlow Models\n",
    "During the integration and compilation process for the Object Detection API, it'll be useful to keep the directories organized in a hierarchial fashion. You can create a new folder named TensorFlow, then use git to clone the TensorFlow Models repo \n",
    "(https://github.com/tensorflow/models) inside the TensorFlow folder. The command should be:\n",
    "\n",
    "`git clone https://github.com/tensorflow/models.git`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your TensorFlow folder should be organized in this format now:\n",
    "\n",
    "`TensorFlow\n",
    "    |-- models\n",
    "        |-- official\n",
    "        |-- research\n",
    "        |-- samples\n",
    "        |-- tutorials`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile Object Detection API\n",
    "We need to compile to proto files within the framework before we can run the API.\n",
    "\n",
    "Navigate to the research directory, then run these commands:\n",
    "\n",
    "`\n",
    "wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip\n",
    "unzip -o protobuf.zip\n",
    "./bin/protoc object_detection/protos/*.proto --python_out=.\n",
    "bash object_detection/dataset_tools/create_pycocotools_package.sh /tmp/pycocotools\n",
    "{sys.executable} -m setup.py sdist\n",
    "(cd slim && {sys.executable} -m setup.py sdist)\n",
    "cd ../..\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to add the object detection API to the local environment by running these commands via python (Or just use cp on terminal):\n",
    "\n",
    "`\n",
    "os.mkdir(\"./packages\")\n",
    "shutil.copy(\"./models/research/dist/object_detection-0.1.tar.gz\",\"./packages/object_detection-0.1.tar.gz\")\n",
    "shutil.copy(\"./models/research/slim/dist/slim-0.1.tar.gz\",\"./packages/slim-0.1.tar.gz\")\n",
    "shutil.copy(\"/tmp/pycocotools/pycocotools-2.0.tar.gz\",\"./packages/pycocotools-2.0.tar.gz\")\n",
    "`\n",
    "\n",
    "Then, go back to terminal and install these packages:\n",
    "\n",
    "`\n",
    "!{sys.executable} -m pip install ./packages/object_detection-0.1.tar.gz\n",
    "!{sys.executable} -m pip install ./packages/slim-0.1.tar.gz\n",
    "!{sys.executable} -m pip install ./packages/pycocotools-2.0.tar.gz\n",
    "` \n",
    "\n",
    "And lastly, from inside the research folder, add the TensorFlow object detection API packages to your PYTHONPATH just to confirm. <PATH_TO_TF> should replace the absolute path to your TensorFlow folder:\n",
    "\n",
    "`\n",
    "export PYTHONPATH=$PYTHONPATH:<PATH_TO_TF>/TensorFlow/models/research:<PATH_TO_TF>/TensorFlow/models/research/slim\n",
    "`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing LabelImg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LabelImg can be downloaded using git, but has a different dependency than TensorFlow, so will require a new virtual environment to run labelImg:\n",
    "\n",
    "`conda create -n labelImg py`\n",
    "\n",
    "Once the virtual environment is created, activate it:\n",
    "\n",
    "`activate labelImg`\n",
    "\n",
    "Create a new directory inside the TensorFlow folder and name it addons. Once inside the new folder, you can clone the labelImg repository using git:\n",
    "\n",
    "`git clone https://github.com/tzutalin/labelImg.git`\n",
    "\n",
    "Inside the virtual environment, you'll need to install the dependencies and compile the labelImg package:\n",
    "\n",
    "`conda install pyqt=4\n",
    "conda install lxml\n",
    "pyrcc4 -py3 -o resources.py resources.qrc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these installation steps for labelImg, you can test it out by changing directory to the labelImg folder and running it:\n",
    "\n",
    "`python labelImg.py`\n",
    "\n",
    "Now we're ready to start training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Object Detector Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the TensorFlow folder, create a new folder named workspace, where we can store all working files. Inside, we can create the directory for our actual project, named SignLanguageAlphabetDetection. The repository should look like this:\n",
    "\n",
    "`TensorFlow\n",
    "    |-- models\n",
    "        |-- official\n",
    "        |-- research\n",
    "        |-- samples\n",
    "        |-- tutorials\n",
    "    |-- addons\n",
    "        |-- labelImg\n",
    "    |-- workspace\n",
    "        |-- SignLanguageAlphabetDetection\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the SignLanguageAlphabetDetection folder, we can further organize our files in such a manner:\n",
    "\n",
    "`SignLanguageAlphabetDetection\n",
    "    |-- annotations\n",
    "    |-- images\n",
    "        |-- train\n",
    "            |-- JPG\n",
    "            |-- XML\n",
    "        |-- test\n",
    "            |-- JPG\n",
    "            |-- XML\n",
    "    |-- models\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Label Map\n",
    "\n",
    "To identify object classes, a label map is required to map each labels to integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile annotations/label_map.pbtxt\n",
    "\n",
    "item {\n",
    "    id: 1\n",
    "    name: 'hand'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Create TensorFlow Records\n",
    "\n",
    "To train the model, we need to convert the annotated XML files into a TensorFlow record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import shutil\n",
    "import os\n",
    "import io\n",
    "import glob\n",
    "from PIL import Image\n",
    "from lxml import etree\n",
    "import random\n",
    "import contextlib2\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.dataset_tools import tf_record_creation_util\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset'\n",
    "train_dir = data_dir + '/train'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "label_map_path = 'annotations/label_map.pbtxt'\n",
    "output_dir = 'tfrecords/'\n",
    "os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map_dict = label_map_util.get_label_map_dict(label_map_path)\n",
    "class_name = 'hand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up filepaths for tensorflow record files to be created from dataset\n",
    "train_output_path = os.path.join(output_dir, 'train.record')\n",
    "test_output_path = os.path.join(output_dir, 'test.record')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many images in dataset\n",
    "training_images = glob.glob(train_dir + \"/JPG/*.jpg\")\n",
    "test_images = glob.glob(test_dir + \"/JPG/*.jpg\")\n",
    "print(\"There are {} training images.\".format(len(training_images)))\n",
    "print(\"There are {} test images.\".format(len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_tf_example(data, label_map_dict, img_path):\n",
    "    \"\"\"\n",
    "    Converts dictionary of a single image and its xml annotation into a Tensorflow compatible example.\n",
    "    \n",
    "    Args:\n",
    "        data (dictionary): contains xml annotation data (image dims, bounding box coordinates and labels)\n",
    "        label_map_dict (dictionary): contains mapping of out_of_stock class to its id\n",
    "        img_path (str): filepath for image to encode\n",
    "    Returns:\n",
    "        TensorFlow Example containing encoded data from xml annotation and image data\n",
    "    \"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        image_contents = tf.read_file(img_path)\n",
    "        image = tf.image.decode_jpeg(image_contents, channels=3)\n",
    "        init_op = tf.initialize_all_tables()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init_op)\n",
    "            try:\n",
    "                tmp = sess.run(image)\n",
    "            except:\n",
    "                print(img_path)\n",
    "    with tf.io.gfile.GFile(img_path, 'rb') as file:\n",
    "        encoded_jpeg = file.read()\n",
    "    encoded_jpeg_io = io.BytesIO(encoded_jpeg)\n",
    "    image = Image.open(encoded_jpeg_io)\n",
    "    if image.format != 'JPEG':\n",
    "        raise ValueError('Image format not JPEG')\n",
    "    width = int(data['size']['width'])\n",
    "    height = int(data['size']['height'])\n",
    "    xmins, xmaxs, ymins, ymaxs = [], [], [], []\n",
    "    classes, classes_text = [], []\n",
    "    \n",
    "    if 'object' in data:\n",
    "        for obj in data['object']:\n",
    "            xmins.append(float(obj['bndbox']['xmin']) / width)\n",
    "            xmaxs.append(float(obj['bndbox']['xmax']) / width)\n",
    "            ymins.append(float(obj['bndbox']['ymin']) / height)\n",
    "            ymaxs.append(float(obj['bndbox']['ymax']) / height)\n",
    "            classes_text.append(class_name.encode('utf8'))\n",
    "            classes.append(label_map_dict[class_name])\n",
    "    feature_dict = {\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/filename': dataset_util.bytes_feature(data['filename'].encode('utf8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(data['filename'].encode('utf8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpeg),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes)\n",
    "    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature_dict))\n",
    "    return example            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_record(output_filename, num_shards, label_map_dict, images):\n",
    "    \"\"\"\n",
    "    Writes a Tensorflow Record file from the xml annotations of provided images and splits up records into shards.\n",
    "    \n",
    "    Args:\n",
    "        output_filename (str): filepath of TensorFlow record to write\n",
    "        num_shards (int): number of shards to divide records into\n",
    "        label_map_dict (dictionary): contains mapping for out_of_stock identifier and label\n",
    "        images ([Str]): list of strings of images' filepaths\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with contextlib2.ExitStack() as tf_record_close_stack:\n",
    "        output_tfrecords = tf_record_creation_util.open_sharded_output_tfrecords(tf_record_close_stack, output_filename, num_shards)\n",
    "        for idx, image in enumerate(images):\n",
    "            if idx % 50 == 0:\n",
    "                print(f\"On image {idx} of {len(images)}.\")\n",
    "            split_path = image.split(\"JPG/\")\n",
    "            xml_path = os.path.join(split_path[0] + \"XML/\" + split_path[1][:-4] + \".xml\")\n",
    "            if not os.path.exists(xml_path):\n",
    "                print(f\"Could not find {xml_path}, ignoring image.\")\n",
    "                continue\n",
    "            with tf.io.gfile.GFile(xml_path, 'r') as file:\n",
    "                xml_str = file.read()\n",
    "            xml = etree.fromstring(xml_str)\n",
    "            data = dataset_util.recursive_parse_xml_to_dict(xml)['annotation']\n",
    "            try:\n",
    "                tf_example = dict_to_tf_example(data, label_map_dict, image)\n",
    "                if tf_example:\n",
    "                    shard_idx = idx % num_shards\n",
    "                    output_tfrecords[shard_idx].write(tf_example.SerializeToString())\n",
    "            except ValueError:\n",
    "                print(f\"Invalid example {xml_path}, ignoring.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensorflow records.\n",
    "create_tf_record(train_output_path, 2, label_map_dict, training_images)\n",
    "create_tf_record(test_output_path, 2, label_map_dict, test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model\n",
    "\n",
    "Before running the training job, we need a model to train on.\n",
    "Check out https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md and select which model to train. Once you've selected a model, copy the link address and download it on terminal via the wget command (Download link from the list):\n",
    "\n",
    "`wget <TAR FILE LINK> (ex. http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz)`\n",
    "\n",
    "Once downloaded and placed in the models folder within your workspace, unzip the tar file via:\n",
    "\n",
    "`tar -xzvf <TAR FILE NAME>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you need to configure the training pipeline job. The unzipped model folder should have a pipeline.config file, in which you need to edit some fields to match the required number of object classes, path to training/test tensorflow records, and path to label map. Look at https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html to see details regarding the pipeline file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_locally.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
